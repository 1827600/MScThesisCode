{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d07f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7990a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "            transforms.ToTensor(), # convert the image to tensor\n",
    "            transforms.Normalize((0.1307,), (0.3081,)) # normalize\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "            transforms.ToTensor(), # convert the image to tensor\n",
    "            transforms.Normalize((0.1307,), (0.3081,)) # normalize \n",
    "    ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37b3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = training_data.data.reshape(-1, 28 * 28).float()\n",
    "y = training_data.targets \n",
    "\n",
    "X_test = test_data.data.reshape(-1, 28 * 28).float()\n",
    "y_test = test_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ced862-4503-421b-8a39-e7f9ad800913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dist_items(ds, n):\n",
    "    n_items = np.array([int(d*n) for d in ds])\n",
    "    prop_difs = ds - n_items/sum(n_items)\n",
    "\n",
    "    while sum(n_items) <n:\n",
    "        i = np.argmax(prop_difs)\n",
    "        n_items[i] += 1\n",
    "        prop_difs = ds - n_items/sum(n_items)\n",
    "    return n_items\n",
    "\n",
    "def distribute_data(X,y,N,alpha,n_labels =10):\n",
    "    sfl = np.random.permutation(len(y))\n",
    "    X = X[sfl]\n",
    "    y = y[sfl]\n",
    "    \n",
    "    alphas = alpha*np.ones((N,))\n",
    "    X_ws = [[] for w in range(N)]\n",
    "    y_ws = [[] for w in range(N)]\n",
    "    next_unused = np.zeros((N,))\n",
    "    \n",
    "    for l in range(n_labels):\n",
    "        ds = np.random.dirichlet(alphas)\n",
    "        indices = y==l\n",
    "\n",
    "        n_l = sum(indices)\n",
    "        n_items = dist_items(ds, n_l)\n",
    "        X_l = X[indices]\n",
    "        y_l = y[indices]\n",
    "        next_unused = 0\n",
    "        for w in range(N):\n",
    "            if n_items[w] >0:\n",
    "                X_ws[w].append(X_l[next_unused:next_unused+n_items[w]])\n",
    "                y_ws[w].append(y_l[next_unused:next_unused+n_items[w]])\n",
    "            next_unused += n_items[w]\n",
    "        \n",
    "    X_workers = [torch.cat(X_ws[w]) for w in range(N) if len(y_ws[w])>0]\n",
    "    y_workers = [torch.cat(y_ws[w]) for w in range(N) if len(y_ws[w])>0]\n",
    "    return X_workers, y_workers\n",
    "def iid_data(X, y,N,m_w):\n",
    "    \n",
    "    sfl = np.random.permutation(len(y))\n",
    "    \n",
    "    X_workers_iid = [X[sfl][m_w*w:m_w*(w+1)] for w in range(N)]\n",
    "    y_workers_iid = [y[sfl][m_w*w:m_w*(w+1)] for w in range(N)]\n",
    "    return X_workers_iid, y_workers_iid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ec020-d206-45a1-bf54-95eb9a22badd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "m_w = 30\n",
    "X2 = torch.cat([X[y==l][0:m_w] for l in range(10)])\n",
    "y2 = torch.cat([y[y==l][0:m_w] for l in range(10)])\n",
    "X_workers_iid, y_workers_iid = iid_data(X2, y2,N,m_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f15c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogRegression(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LogRegression, self).__init__()\n",
    "            self.linear1 = nn.Linear(28*28, 10, bias = True)\n",
    "        def forward(self, x, verbose=False):\n",
    "            out = self.linear1(x)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd72608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to calculate the accuracy of data of a given model\n",
    "def calculate_accuracy(mdl, X, y):\n",
    "    mdl.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = mdl(X.reshape(len(X), 28*28).float())\n",
    "        y_pred = torch.softmax(y_pred, 1)\n",
    "        y_pred = torch.argmax(y_pred, dim = 1)\n",
    "\n",
    "        accuracy = torch.sum(y_pred == y)/len(y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b2955-43e3-4103-936b-d37a73f068cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a566eba-bc04-42ce-8614-b19e195c84e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def share_data(X_workers1,y_workers1, p, rf=1):\n",
    "    N = len(X_workers1)\n",
    "\n",
    "    X_ws = [X_workers1[w].clone() for w in range(N)]\n",
    "    y_ws = [y_workers1[w].clone() for w in range(N)]\n",
    "    \n",
    "    X = torch.cat(X_ws)\n",
    "    y = torch.cat(y_ws)\n",
    "    ms = np.array([len(X_ws[w]) for w in range(N)])\n",
    "    ms_original = ms.copy()\n",
    "    m = sum(ms)\n",
    "    \n",
    "\n",
    "    c = int(p*m)\n",
    "    shared_indices = np.random.choice(m, c, replace=False)\n",
    "    lst = np.array([sum(ms[0:i]) for i in range(1,len(ms)+1)]) #list with the index of first datapoint for the next worker in X\n",
    "    owners = [np.argmax(lst>i) for i in shared_indices]\n",
    "    shared_indices_worker = [[] for w in range(N)]\n",
    "    for i, si in enumerate(shared_indices):\n",
    "        owner = np.argmax(lst>si) # owner of the shared datapoint\n",
    "        si_w = si - sum(ms_original[0:owner])\n",
    "        shared_indices_worker[owner].append(si_w)\n",
    "\n",
    "        \n",
    "        possible_receivers = [w for w in range(N) if w!= owner]\n",
    "        receivers = np.random.choice(possible_receivers, rf,replace = False)\n",
    "\n",
    "        x_shared = torch.unsqueeze(X[si], 0)\n",
    "        y_shared = torch.unsqueeze(y[si], 0)\n",
    "        for receiver in receivers:\n",
    "            X_ws[receiver] = torch.cat((X_ws[receiver],x_shared.clone()))\n",
    "            y_ws[receiver] = torch.cat((y_ws[receiver],y_shared.clone()))\n",
    "            ms[receiver] += 1\n",
    "    loss_weights_workers = [torch.ones((len(y_ws[w]),)) for w in range(N)]\n",
    "    for w in range(N):\n",
    "        if ms[w] != len(y_ws[w]):\n",
    "            print(ms[w],len(y_ws))\n",
    "        for si_w in shared_indices_worker[w]:\n",
    "            loss_weights_workers[w][si_w] = 1/(rf+1)\n",
    "        if ms[w] > ms_original[w]:\n",
    "            loss_weights_workers[w][ms_original[w]-ms[w]:] = loss_weights_workers[w][ms_original[w]-ms[w]:]/(rf+1)\n",
    "            \n",
    "    return X_ws, y_ws, loss_weights_workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7719b7-8a24-4867-b6bb-f7e240751631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_estimator_second_moment(\n",
    "    model, p, X_workers, y_workers, weights_workers=None, n_iter=25\n",
    "):\n",
    "    N = len(X_workers)\n",
    "\n",
    "    if weights_workers is None:\n",
    "        weights_workers = [torch.ones(len(X_workers[w])) for w in range(N)]\n",
    "\n",
    "    m = sum([ws.sum() for ws in weights_workers])\n",
    "\n",
    "    gradient_squared_norms = []\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if True:\n",
    "        for iteration in range(n_iter):\n",
    "            model.train()\n",
    "            choose_ws = [np.random.choice(2, p=[p_straggler, 1 - p_straggler]) for w in range(N)]\n",
    "            ws = [i for i in range(N) if choose_ws[i] == 1]\n",
    "\n",
    "            if len(ws) > 0:\n",
    "                inputs = torch.cat([X_workers[w] for w in ws])\n",
    "                labels = torch.cat([y_workers[w] for w in ws])\n",
    "                weights = torch.cat([weights_workers[w] for w in ws])\n",
    "\n",
    "                model.zero_grad()\n",
    "                y_pred = model(inputs)\n",
    "                losses = criterion(y_pred, labels.type(torch.long)) * weights\n",
    "                loss = losses.sum() / ((1 - p_straggler) * m)\n",
    "                loss.backward()\n",
    "\n",
    "                gradient = model.linear1.weight.grad\n",
    "                gradient_squared_norm = torch.norm(gradient) ** 2\n",
    "\n",
    "                gradient = model.linear1.bias.grad\n",
    "                gradient_squared_norm += torch.norm(gradient) ** 2\n",
    "\n",
    "                gradient_squared_norms.append(gradient_squared_norm)\n",
    "\n",
    "    return np.mean(gradient_squared_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a303a-5e64-42f7-bc22-f5ce4f70d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_simulation(p_straggler, X_workers, y_workers, weights_workers):\n",
    "    accuracies = np.zeros(n_iter)\n",
    "    moments = np.zeros(n_iter)\n",
    "\n",
    "    N = len(X_workers)\n",
    "    m = sum(weights.sum() for weights in weights_workers)\n",
    "    model = LogRegression()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    for iteration in range(n_iter):\n",
    "        accuracy = calculate_accuracy(model, X_test, y_test)\n",
    "        accuracies[iteration] = accuracy\n",
    "        model.train()\n",
    "        choose_ws = [np.random.choice(2, p = [p_straggler, 1-p_straggler]) for w in range(N)]\n",
    "        ws = [i for i in range(N) if choose_ws[i]==1 ]\n",
    "        if len(ws) > 0:\n",
    "            inputs = torch.cat([X_workers[w] for w in ws] )\n",
    "            labels = torch.cat([y_workers[w] for w in ws])\n",
    "            weights = torch.cat([weights_workers[w] for w in ws])\n",
    "\n",
    "            model.zero_grad()\n",
    "            y_pred = model(inputs)\n",
    "            losses = criterion(y_pred, labels.type(torch.long)) * weights\n",
    "            loss = losses.sum() / ((1 - p_straggler) * m)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        moments[iteration] = gradient_estimator_second_moment(model, p_straggler, X_workers, y_workers, weights_workers)\n",
    "\n",
    "    return accuracies, moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a0f0f-ce75-4c93-b897-9826cc790d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "n_iter = 50\n",
    "n_sim  = 200\n",
    "alpha = 0.1\n",
    "m_w = 30\n",
    "N = 10\n",
    "p_straggler_list = [0.3,0.5,0.8]\n",
    "\n",
    "prfs_comm = [(0.3/4,4),(0.3/3,3),(0.3/2,2), (0.3,1)]\n",
    "prfs_data = [(0.3,7),(0.3,5),(0.3,2), (0.3,1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea8c32-81e0-4d6a-bfea-087662507bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc977a8-9a7e-4c30-a127-ffc85f0a272f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model for iid data\n",
    "\n",
    "accuracies_iid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "moments_iid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "\n",
    "weights_workers = [torch.ones(m_w,) for w in range(N)]\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    p_stragglers = np.ones((N,))*p_straggler\n",
    "    for sim in tqdm(range(n_sim),desc=f\"Running simulations for p = {p_straggler}\"):\n",
    "        X_workers_iid, y_workers_iid = iid_data(X2,y2,10,m_w)\n",
    "        accuracies, moments = run_simulation(p_straggler, X_workers_iid, y_workers_iid, weights_workers)\n",
    "        accuracies_iid[i_straggler,sim, :] = accuracies\n",
    "        moments_iid[i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuracies_iid\", accuracies_iid)\n",
    "np.save(\"thesisdata/moments_iid\",moments_iid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdc897-5791-4381-afd0-c2d9fc58720b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ccd83d-5ec8-4b20-be71-ccdbca65c576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model for non-iid dirichlet data\n",
    "\n",
    "accuracies_noniid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "moments_noniid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    p_stragglers = np.ones((N,))*p_straggler\n",
    "    for sim in tqdm(range(n_sim),desc=f\"Running simulations for p = {p_straggler}\"):\n",
    "        X_workers,y_workers = distribute_data(X2,y2,N,alpha)\n",
    "        weights_workers = [torch.ones(len(X_workers[w]),) for w in range(len(X_workers))] \n",
    "        accuracies, moments = run_simulation(p_straggler, X_workers, y_workers, weights_workers)\n",
    "        accuracies_noniid[i_straggler,sim, :] = accuracies\n",
    "        moments_noniid[i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuracies_noniid\", accuracies_noniid)\n",
    "np.save(\"thesisdata/moments_noniid\", moments_noniid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625fa88-2015-4c8e-8368-37076dc56bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model with different values of p/rf and dirichlet distributed data\n",
    "\n",
    "accuracies_comm = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "moments_comm = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    \n",
    "    for i, prf in enumerate(prfs_comm):\n",
    "        p,rf = prf\n",
    "        for sim in tqdm(range(n_sim),desc=f\"Running simulations for p,c,d = {p_straggler,p,rf}\"):\n",
    "            X_workers, y_workers = distribute_data(X2,y2,10,alpha)\n",
    "            X_workers_share, y_workers_share, weights_workers = share_data(X_workers,y_workers, p, rf =rf)\n",
    "            accuracies, moments = run_simulation(p_straggler, X_workers_share, y_workers_share, weights_workers)\n",
    "            accuracies_comm[i,i_straggler,sim, :] = accuracies\n",
    "            moments_comm[i,i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuracies_comm\", accuracies_comm)\n",
    "np.save(\"thesisdata/moments_comm\", moments_comm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b5107-bb03-4f01-ba44-08d1cbd2c63a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model with different values of p/rf and dirichlet distributed data\n",
    "\n",
    "\n",
    "accuracies_data = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "moments_data = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    \n",
    "    for i, prf in enumerate(prfs_data):\n",
    "        p,rf = prf\n",
    "        for sim in tqdm(range(n_sim),desc=f\"Running simulations for p,c,d = {p_straggler,p,rf}\"):\n",
    "            X_workers, y_workers = distribute_data(X2,y2,10,alpha)\n",
    "            X_workers_share, y_workers_share, weights_workers = share_data(X_workers,y_workers, p, rf =rf)\n",
    "            accuracies, moments = run_simulation(p_straggler, X_workers_share, y_workers_share, weights_workers)\n",
    "            accuracies_data[i,i_straggler,sim, :] = accuracies\n",
    "            moments_data[i,i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuracies_data\", accuracies_data)\n",
    "np.save(\"thesisdata/moments_data\", moments_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc295f0c-91e2-4bab-9b5a-197fc9cdba1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783411c-3693-46f1-92a9-e9a3a3448eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Divide the data without dirichlet distribution\n",
    "X_workers = []\n",
    "y_workers = []\n",
    "\n",
    "for l in range(10):\n",
    "    X_workers.append(X2[y2 == l].clone())\n",
    "    y_workers.append(y2[y2 == l].clone())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79e676-e146-40cd-adf9-14a50feb263b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model for non-iid dirichlet data\n",
    "\n",
    "accuraciesHom_noniid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "momentsHom_noniid = np.zeros((len(p_straggler_list),n_sim,n_iter))\n",
    "\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    p_stragglers = np.ones((N,))*p_straggler\n",
    "    for sim in tqdm(range(n_sim),desc=f\"Running simulations for p = {p_straggler}\"):\n",
    "        weights_workers = [torch.ones(len(X_workers[w]),) for w in range(len(X_workers))] \n",
    "        accuracies, moments = run_simulation(p_straggler, X_workers, y_workers, weights_workers)\n",
    "        accuraciesHom_noniid[i_straggler,sim, :] = accuracies\n",
    "        momentsHom_noniid[i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuraciesHom_noniid\", accuraciesHom_noniid)\n",
    "np.save(\"thesisdata/momentsHom_noniid\", momentsHom_noniid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f718c8f-a7c1-4a13-9de8-77c89b989d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model with different values of p/rf\n",
    "\n",
    "accuraciesHom_comm = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "momentsHom_comm = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    \n",
    "    for i, prf in enumerate(prfs_comm):\n",
    "        p,rf = prf\n",
    "        for sim in tqdm(range(n_sim),desc=f\"Running simulations for p,c,d = {p_straggler,p,rf}\"):\n",
    "            X_workers_share, y_workers_share, weights_workers = share_data(X_workers,y_workers, p, rf =rf)\n",
    "            accuracies, moments = run_simulation(p_straggler, X_workers_share, y_workers_share, weights_workers)\n",
    "            accuraciesHom_comm[i,i_straggler,sim, :] = accuracies\n",
    "            momentsHom_comm[i,i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuraciesHom_comm\", accuraciesHom_comm)\n",
    "np.save(\"thesisdata/momentsHom_comm\", momentsHom_comm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b82090-3b21-41b9-91e8-c48ed83609b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model with different values of p/rf and\n",
    "\n",
    "\n",
    "accuraciesHom_data = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "momentsHom_data = np.zeros((len(prfs_comm),len(p_straggler_list),n_sim, int(n_iter)))\n",
    "\n",
    "for i_straggler,p_straggler in enumerate(p_straggler_list):\n",
    "    \n",
    "    for i, prf in enumerate(prfs_data):\n",
    "        p,rf = prf\n",
    "        for sim in tqdm(range(n_sim),desc=f\"Running simulations for p,c,d = {p_straggler,p,rf}\"):\n",
    "            X_workers_share, y_workers_share, weights_workers = share_data(X_workers,y_workers, p, rf =rf)\n",
    "            accuracies, moments = run_simulation(p_straggler, X_workers_share, y_workers_share, weights_workers)\n",
    "            accuraciesHom_data[i,i_straggler,sim, :] = accuracies\n",
    "            momentsHom_data[i,i_straggler,sim, :] = moments\n",
    "np.save(\"thesisdata/accuraciesHom_data\", accuraciesHom_data)\n",
    "np.save(\"thesisdata/momentsHom_data\", momentsHom_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39291e52-3206-40bf-acf6-f472da52f284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train model with increased straggler probability with replication\n",
    "\n",
    "p_straggler = 0.8\n",
    "accuraciesHom_data_strag = np.zeros((len(prfs_comm),n_sim, int(n_iter)))\n",
    "momentsHom_data_strag = np.zeros((len(prfs_comm),n_sim, int(n_iter)))\n",
    "\n",
    "\n",
    "for i, prf in enumerate(prfs_data):\n",
    "    p,rf = prf\n",
    "    for sim in tqdm(range(n_sim),desc=f\"Running simulations for p,c,d = {p_straggler,p,rf}\"):\n",
    "        X_workers_share, y_workers_share, weights_workers = share_data(X_workers,y_workers, p, rf =rf)\n",
    "        accuracies, moments = run_simulation(p_straggler+(rf/200), X_workers_share, y_workers_share, weights_workers)\n",
    "        accuraciesHom_data_strag[i,sim, :] = accuracies\n",
    "        momentsHom_data_strag[i,sim, :] = moments \n",
    "np.save(\"thesisdata/accuraciesHom_data_strag\", accuraciesHom_data_strag)\n",
    "np.save(\"thesisdata/momentsHom_data_strag\", momentsHom_data_strag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
